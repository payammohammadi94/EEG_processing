{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9fa9c-0921-4211-9311-f6079f6d527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal,stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.fft import fft , ifft\n",
    "import matplotlib.pyplot as plt \n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,corrmap)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de506256-d6fe-4b2d-973b-2a98f0866ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "\n",
    "'''\n",
    "TOTAL_PATH_T_1_3 = [\n",
    "    [[s1],[s2],...,[s6]], ---->T1\n",
    "    [[s1],[s2],...,[s6]], ---->T2\n",
    "    [[s1],[s2],...,[s6]], ---->T3\n",
    "]\n",
    "'''\n",
    "\n",
    "TOTAL_PATH_T_1_3 = []\n",
    "\n",
    "\n",
    "\n",
    "#مقدار فور را برای ۳ تحریک تنظیم می‌کنیم.\n",
    "for T in range(1,4):\n",
    "    TOTAL_PATH_SUBJECT_1_6_T = []\n",
    "    #مقدار فور را برای ۶ سابجکت تنظیم کرده ایم\n",
    "    for subject in range(1,7):\n",
    "        \"\"\"\n",
    "            در اینجا اومدیم نحوه گرفتن داده ها برای تحریک های مخنلف را جدا کردیم. برای گرفتن داده ی سابجکت ۱ تا ۶ برای تحریک شماره ۱\n",
    "            /Directions_and_Time_T1/*.mat\n",
    "            برای گرفتن داده های سابجکت شماره ۱تا ۶ تحریک شماره ۲\n",
    "            /Directions_and_Time_T2/*.mat\n",
    "            برای گرفتن داده های سابجکت ۱تا ۶ برای تحریک شماره ۳\n",
    "            /Directions_and_Time_T3/*.mat\n",
    "        \"\"\" \n",
    "        subject_T = glob(PATH+f'/s{subject}/Directions_and_Time_T{T}/*.mat')\n",
    "        TOTAL_PATH_SUBJECT_1_6_T.append(subject_T)\n",
    "    \n",
    "    TOTAL_PATH_T_1_3.append(TOTAL_PATH_SUBJECT_1_6_T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583015b2-f8ab-4122-97c4-a7eea57870c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocessing data without ICA\n",
    "\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "\n",
    "frequency_band = np.array[[0.1,4,8,12,30],[4,8,12,30,70]]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t1.append(re_for_get_label.replace(\"'\",''))\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        DATA_RAW.append(raw['data'][0])\n",
    "        raw.plot(show_scrollbars=False, show_scalebars=False)\n",
    "        filt_raw=raw.filter(l_freq=1, h_freq=40)\n",
    "        filt_raw.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        \n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "    \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger=np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1=np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d2122-7bfc-41eb-b0f9-31f19b762377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "    \n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "\n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        \n",
    "        filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "        \n",
    "        \n",
    "        ica = ICA(n_components=15, max_iter='auto', random_state=97)\n",
    "        ica.fit(filt_raw)\n",
    "        ica.apply(filt_raw)\n",
    "\n",
    "        raw_down = filt_raw.resample(sfreq=80)\n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "        \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    \n",
    "    np.save(PATH_SAVE+f'Data_CLEAN_ICA_s{subject}_T{T_Couner}',DATA_RAW_DOWN)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64226a41-9ee0-470c-bc6d-ed03d68cd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[1][0]\n",
    "Temp = loadmat(s_1[20])\n",
    "data = 7e-7*Temp['EEG_Data']\n",
    "data = data.transpose()\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label = re_for_get_label.replace(\"'\",'')\n",
    "N = len(data[:,0])\n",
    "fs = 2000\n",
    "rf = np.linspace(0,fs/4,int(np.round(N/2)))\n",
    "\n",
    "fft_data = fft(data[:,0],n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c3b78-9175-4dbc-b261-75eb162e2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(rf[1:],np.abs(fft_data[1:int(np.round(N/2))]*10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae5376-1a09-4d70-8aa5-fcd524aaeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "s_1 = TOTAL_PATH_T_1_3[1][3]\n",
    "Temp = loadmat(s_1[15])\n",
    "data = Temp['EEG_Data']\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21 #برای اینکه بفهمد که همه کانال ها سیگنال (ای ای جی) می‌گیرد\n",
    "\n",
    "sampling_freq = 2000\n",
    "\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "raw = mne.io.RawArray(data, info)\n",
    "raw.crop(tmax=1.8)\n",
    "filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "filt_raw.resample(sfreq=sampling_freq) #بعد از کراپ کردن دیتا دوباره می‌ایم یک نمونه برداری می‌کنیم که سایز ماتریس داده ها برای همه دیتا ها یکی شود\n",
    "filt_raw['data'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837f88-3d49-4451-bf44-a592287b4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[0][1]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c965d-eee4-4c05-9502-623a47d42753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just one data\n",
    "#denoising for one signal\n",
    "s_1 = TOTAL_PATH_T_1_3[0][2]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)\n",
    "fs = 2000\n",
    "f_nyq = fs/2\n",
    "Wn = [1,40]/np.float_(f_nyq)\n",
    "(b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "rf = rf[rf<50]\n",
    "for i in range(0,chanel_num):\n",
    "    #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "    sigA = data[i,:]\n",
    "    data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "    print(signal.filtfilt(b,a,sigA).shape)\n",
    "    Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "    fourier_domain[i,:] = Fsig_dn\n",
    "    \n",
    "    # plt.figure(figsize=(12,8),dpi = 300)\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "    # plt.legend()\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f'{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3230159-c831-4481-afd7-d1699c04b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b311b-8d13-43c0-ab82-a0a3a94a9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi = 300)\n",
    "plt.subplot(1,2,1)\n",
    "plt.stem(rf,np.abs(fourier_domain[2,:rf.shape[0]]),label=f'channel {i+1}- frequency domain')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(data_filter[2,:],label=f'channel {i+1}- time domain')\n",
    "plt.legend()\n",
    "plt.savefig(f'{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea22cd-260f-44cf-992e-ac9c7c53bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Couner = 1 \n",
    "MIN = 5000\n",
    "MAX = 0\n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        for j in path_for_t[i]:\n",
    "            Temp = loadmat(j)\n",
    "            data = Temp['EEG_Data']\n",
    "            \n",
    "            a,b = data.shape\n",
    "            if b < MIN:\n",
    "                MIN = b\n",
    "            if b > MAX :\n",
    "                MAX = b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72dfc4-bb02-4da8-91fb-019bd3a3ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    Wn = [1,40]/np.float_(f_nyq)\n",
    "    (b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        \n",
    "        a = 7e-7\n",
    "        \n",
    "        data = a * Temp['EEG_Data']\n",
    "        \n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label = re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "        \n",
    "        chanel_num = data.shape[0]\n",
    "        sample_for_data = data.shape[1]\n",
    "        \n",
    "        data_filter = np.zeros_like(data)\n",
    "        fourier_domain = np.zeros_like(data)\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "    rf = rf[rf<50]\n",
    "    \n",
    "    for i in range(0,chanel_num):\n",
    "        #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "        sigA = data[i,:]\n",
    "        data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "        \n",
    "        Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "        \n",
    "        fourier_domain[i,:] = Fsig_dn\n",
    "        \n",
    "        # plt.figure(figsize=(12,8),dpi = 300)\n",
    "        # plt.subplot(1,2,1)\n",
    "        # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "        # plt.legend()\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "        # plt.legend()\n",
    "        # plt.savefig(f'{i}.png')\n",
    "        \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger = np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1 = np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bf767-186a-4a50-9d69-4251e33df802",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "subject_T = glob(PATH+f'/s{1}/Directions_and_Time_T{1}/*.mat')\n",
    "data_raw_path = subject_T[0]\n",
    "\n",
    "def filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low,f_high):\n",
    "    \n",
    "    data_filter = np.zeros_like(data)\n",
    "\n",
    "    Wn = [f_low,f_high]/np.float_(f_nyq)\n",
    "    \n",
    "    (b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    for channel_signal in range(0,channel_num):\n",
    "        \n",
    "        data_each_channel = data[channel_signal,:]\n",
    "        data_filter[channel_signal,:] = signal.filtfilt(b,a,data_each_channel)\n",
    "\n",
    "    return data_filter\n",
    "    \n",
    "def feature_selection(data,channel_num):\n",
    "    num_feature = 5 #mean var power skew kur \n",
    "    feature_selections_total = np.zeros((21,num_feature))\n",
    "    # 30 why?\n",
    "    #5 band that each band has 6 features\n",
    "    #data = delta that 21*n, theta 21*n alpha 21*n, beta 21*n and gamma 21*n \n",
    "    low_band_zeros_matrix = 0\n",
    "    high_band_zeros_matrix = num_feature\n",
    "    \n",
    "    for i in range(0,channel_num):\n",
    "        \n",
    "        data_for_feature_extraction = data[i,:]\n",
    "        \n",
    "        MEAN = np.mean(data_for_feature_extraction)\n",
    "        VAR = np.var(data_for_feature_extraction)\n",
    "        POWER = np.mean(np.power(data_for_feature_extraction,2))\n",
    "        SKEW = stats.skew(data_for_feature_extraction)\n",
    "        KUR = stats.kurtosis(data_for_feature_extraction)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        # مثلا کانال ۱ دارای ۵ تا باند هست و هر باند ۶ فیچر استخراج می‌کنیم پس هر کانال ۳۰ قیچر داره\n",
    "        \n",
    "        feature_selections_total[i,:] = (MEAN,VAR,POWER,SKEW,KUR)\n",
    "        \n",
    "        \n",
    "        #low_band_zeros_matrix += 5\n",
    "        #high_band_zeros_matrix +=5\n",
    "\n",
    "        #پس این خروجی ماتریس مربوط به ۳۰ ویژگی تمام کانال های یک سیگنال است.\n",
    "    return feature_selections_total\n",
    "    \n",
    "\n",
    "\n",
    "def seperate_band(data,channel_num,sample_for_data,fs,f_nyq):\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند دلتا را دارد\n",
    "    delta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=1,f_high=4)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند تتا را دارد\n",
    "    theta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=4,f_high=8)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند آلفا را دارد     \n",
    "    alpha = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=8,f_high=12)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند بتا را دارد\n",
    "    beta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=12,f_high=30)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که سیگنال های باند گاما در هر کانال را دارد\n",
    "    gamma = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=30,f_high=40)\n",
    "\n",
    "    return (delta,theta,alpha,beta,gamma)\n",
    "\n",
    "def frequency_domain(data):\n",
    "    f_r[idx_delta],np.abs(fft_data[:int(np.round(N/2))][idx_delta])\n",
    "    idx_delta = np.logical_and(f_r >= 1, f_r <= 4)\n",
    "    \n",
    "    frequency_band_delta = \n",
    "    idx_theta = np.logical_and(f_r >= 4, f_r <= 8)\n",
    "    idx_alpha = np.logical_and(f_r >= 8, f_r <= 12)\n",
    "    idx_beta = np.logical_and(f_r >= 12, f_r <= 30)\n",
    "    idx_gamma = np.logical_and(f_r >= 30, f_r <= 40)\n",
    "\n",
    "\n",
    "def read_raw_data(path):\n",
    "    \n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    \n",
    "    \n",
    "    Temp = loadmat(path)\n",
    "    a = 7e-7\n",
    "    data = a * Temp['EEG_Data']\n",
    "    \n",
    "    #determine the label for data\n",
    "    re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "    re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "    label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "\n",
    "    #determine channel number eeg signal i\n",
    "    channel_num = data.shape[0]\n",
    "    #determine sample number for eeg signal i\n",
    "    sample_for_data = data.shape[1]\n",
    "\n",
    "    #determine 0 - 40 hz\n",
    "    data_denoising = filter_noisy_data(data, channel_num, sample_for_data, fs, f_nyq, f_low=1,f_high=40)\n",
    "    #####################################################seperate frequency band\n",
    "    (delta_time,theta_time,alpha_time,beta_time,gamma_time) = seperate_band(data_denoising,channel_num,sample_for_data,fs,f_nyq)\n",
    "    #####################################################Feature Extraction\n",
    "    delta_feature_time = feature_selection(delta_time,21) #فیچر باند دلتا هر ۲۱ کانال در آن می‌باشد\n",
    "    theta_feature_time = feature_selection(theta_time,21)#فیچر باند تتا هر ۲۱ کانال در آن می‌باشد\n",
    "    alpha_feature_time = feature_selection(alpha_time,21)#فیچر باند آلفا هر ۲۱ کانال در آن می‌باشد\n",
    "    beta_feature_time = feature_selection(beta_time,21)#فیچر باند بتا هر ۲۱ کانال در آن می‌باشد\n",
    "    gamma_feature_time = feature_selection(gamma_time,21)#فیچر باند گاما هر ۲۱ کانال در آن می‌باشد\n",
    "    #######################################################\n",
    "    #میخوایم برای هر کانال تمام فیچر های هر باند را پشت سر هم بندازیم\n",
    "    num_features_for_each_channel = 25\n",
    "    time_domain_combine_feature_each_band = np.zeros((channel_num,num_features_for_each_channel))\n",
    "    \n",
    "    for chan_num in  range(0,channel_num):\n",
    "        time_domain_combine_feature_each_band[chan_num,:] = np.ravel(np.vstack((delta_feature_time[chan_num,:],theta_feature_time[chan_num,:],alpha_feature_time[chan_num,:],beta_feature_time[chan_num,:],gamma_feature_time[chan_num,:])))\n",
    "    \n",
    "    total_feature_selection_for_each_eeg_signal_time_domain = np.ravel(time_domain_combine_feature_each_band)\n",
    "    ##################################################################\n",
    "\n",
    "    return data_denoising\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a1101-0e55-4556-b961-aea180beb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_denoising = read_raw_data(data_raw_path)\n",
    "N = data_denoising.shape[1]\n",
    "fs = 2000\n",
    "fft_data = fft(data_denoising[1,:],N)\n",
    "f_r = np.linspace(0,fs/2,int(np.round(N/2)))\n",
    "f_r_total = np.concatenate((f_r,f_r[::-1]))\n",
    "fft_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff64cc9-86f3-4c01-9957-ad1fef3cd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(21):\n",
    "    plt.stem(f_r[f_r<50],fft_data[i,:f_r[f_r<50].shape[0]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67453f-d028-445b-9620-6fe35061f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_delta = np.logical_and(f_r >= 1, f_r <= 4)\n",
    "idx_theta = np.logical_and(f_r >= 4, f_r <= 8)\n",
    "idx_alpha = np.logical_and(f_r >= 8, f_r <= 12)\n",
    "idx_beta = np.logical_and(f_r >= 12, f_r <= 30)\n",
    "idx_gamma = np.logical_and(f_r >= 30, f_r <= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf0697-2ba0-44b8-a4f6-276e30416dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(f_r[idx_delta],np.abs(fft_data[:int(np.round(N/2))][idx_delta]),'r')\n",
    "plt.stem(f_r[idx_theta],np.abs(fft_data[:int(np.round(N/2))][idx_theta]),'g')\n",
    "plt.stem(f_r[idx_alpha],np.abs(fft_data[:int(np.round(N/2))][idx_alpha]),'y')\n",
    "plt.stem(f_r[idx_beta],np.abs(fft_data[:int(np.round(N/2))][idx_beta]),'b')\n",
    "plt.stem(f_r[idx_gamma],np.abs(fft_data[:int(np.round(N/2))][idx_gamma]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f1465-7ef1-471e-ba5e-737891a3d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(f_r[f_r<40],np.abs(fft_data[:int(np.round(N/2))][f_r<40]),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0949793-9dcc-47e1-a960-3b1a67b03715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data[:int(np.round(N/2))][idx_gamma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63471b13-61da-41f8-847a-495b3f0cc1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
