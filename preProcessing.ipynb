{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9fa9c-0921-4211-9311-f6079f6d527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal,stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.fft import fft , ifft\n",
    "import matplotlib.pyplot as plt \n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,corrmap)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de506256-d6fe-4b2d-973b-2a98f0866ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "\n",
    "'''\n",
    "TOTAL_PATH_T_1_3 = [\n",
    "    [[s1],[s2],...,[s6]], ---->T1\n",
    "    [[s1],[s2],...,[s6]], ---->T2\n",
    "    [[s1],[s2],...,[s6]], ---->T3\n",
    "]\n",
    "'''\n",
    "\n",
    "TOTAL_PATH_T_1_3 = []\n",
    "\n",
    "\n",
    "\n",
    "#مقدار فور را برای ۳ تحریک تنظیم می‌کنیم.\n",
    "for T in range(1,4):\n",
    "    TOTAL_PATH_SUBJECT_1_6_T = []\n",
    "    #مقدار فور را برای ۶ سابجکت تنظیم کرده ایم\n",
    "    for subject in range(1,7):\n",
    "        \"\"\"\n",
    "            در اینجا اومدیم نحوه گرفتن داده ها برای تحریک های مخنلف را جدا کردیم. برای گرفتن داده ی سابجکت ۱ تا ۶ برای تحریک شماره ۱\n",
    "            /Directions_and_Time_T1/*.mat\n",
    "            برای گرفتن داده های سابجکت شماره ۱تا ۶ تحریک شماره ۲\n",
    "            /Directions_and_Time_T2/*.mat\n",
    "            برای گرفتن داده های سابجکت ۱تا ۶ برای تحریک شماره ۳\n",
    "            /Directions_and_Time_T3/*.mat\n",
    "        \"\"\" \n",
    "        subject_T = glob(PATH+f'/s{subject}/Directions_and_Time_T{T}/*.mat')\n",
    "        TOTAL_PATH_SUBJECT_1_6_T.append(subject_T)\n",
    "    \n",
    "    TOTAL_PATH_T_1_3.append(TOTAL_PATH_SUBJECT_1_6_T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583015b2-f8ab-4122-97c4-a7eea57870c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocessing data without ICA\n",
    "\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "\n",
    "frequency_band = np.array[[0.1,4,8,12,30],[4,8,12,30,70]]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t1.append(re_for_get_label.replace(\"'\",''))\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        DATA_RAW.append(raw['data'][0])\n",
    "        raw.plot(show_scrollbars=False, show_scalebars=False)\n",
    "        filt_raw=raw.filter(l_freq=1, h_freq=40)\n",
    "        filt_raw.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        \n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "    \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger=np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1=np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d2122-7bfc-41eb-b0f9-31f19b762377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "    \n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "\n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        \n",
    "        filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "        \n",
    "        \n",
    "        ica = ICA(n_components=15, max_iter='auto', random_state=97)\n",
    "        ica.fit(filt_raw)\n",
    "        ica.apply(filt_raw)\n",
    "\n",
    "        raw_down = filt_raw.resample(sfreq=80)\n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "        \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    \n",
    "    np.save(PATH_SAVE+f'Data_CLEAN_ICA_s{subject}_T{T_Couner}',DATA_RAW_DOWN)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64226a41-9ee0-470c-bc6d-ed03d68cd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[1][0]\n",
    "Temp = loadmat(s_1[20])\n",
    "data = 7e-7*Temp['EEG_Data']\n",
    "data = data.transpose()\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label = re_for_get_label.replace(\"'\",'')\n",
    "N = len(data[:,0])\n",
    "fs = 2000\n",
    "rf = np.linspace(0,fs/4,int(np.round(N/2)))\n",
    "\n",
    "fft_data = fft(data[:,0],n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c3b78-9175-4dbc-b261-75eb162e2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(rf[1:],np.abs(fft_data[1:int(np.round(N/2))]*10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae5376-1a09-4d70-8aa5-fcd524aaeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "s_1 = TOTAL_PATH_T_1_3[1][3]\n",
    "Temp = loadmat(s_1[15])\n",
    "data = Temp['EEG_Data']\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21 #برای اینکه بفهمد که همه کانال ها سیگنال (ای ای جی) می‌گیرد\n",
    "\n",
    "sampling_freq = 2000\n",
    "\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "raw = mne.io.RawArray(data, info)\n",
    "raw.crop(tmax=1.8)\n",
    "filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "filt_raw.resample(sfreq=sampling_freq) #بعد از کراپ کردن دیتا دوباره می‌ایم یک نمونه برداری می‌کنیم که سایز ماتریس داده ها برای همه دیتا ها یکی شود\n",
    "filt_raw['data'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837f88-3d49-4451-bf44-a592287b4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[0][1]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c965d-eee4-4c05-9502-623a47d42753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just one data\n",
    "#denoising for one signal\n",
    "s_1 = TOTAL_PATH_T_1_3[0][2]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)\n",
    "fs = 2000\n",
    "f_nyq = fs/2\n",
    "Wn = [1,40]/np.float_(f_nyq)\n",
    "(b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "rf = rf[rf<60]\n",
    "for i in range(0,chanel_num):\n",
    "    #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "    sigA = data[i,:]\n",
    "    data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "    print(signal.filtfilt(b,a,sigA).shape)\n",
    "    Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "    fourier_domain[i,:] = Fsig_dn\n",
    "    \n",
    "    # plt.figure(figsize=(12,8),dpi = 300)\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "    # plt.legend()\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f'{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3230159-c831-4481-afd7-d1699c04b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b311b-8d13-43c0-ab82-a0a3a94a9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi = 300)\n",
    "plt.subplot(1,2,1)\n",
    "plt.stem(rf,np.abs(fourier_domain[2,:rf.shape[0]]),label=f'channel {i+1}- frequency domain')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(data_filter[2,:],label=f'channel {i+1}- time domain')\n",
    "plt.legend()\n",
    "plt.savefig(f'{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea22cd-260f-44cf-992e-ac9c7c53bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Couner = 1 \n",
    "MIN = 5000\n",
    "MAX = 0\n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        for j in path_for_t[i]:\n",
    "            Temp = loadmat(j)\n",
    "            data = Temp['EEG_Data']\n",
    "            \n",
    "            a,b = data.shape\n",
    "            if b < MIN:\n",
    "                MIN = b\n",
    "            if b > MAX :\n",
    "                MAX = b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72dfc4-bb02-4da8-91fb-019bd3a3ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    Wn = [1,40]/np.float(f_nyq)\n",
    "    (b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        \n",
    "        a = 7e-7\n",
    "        \n",
    "        data = a * Temp['EEG_Data']\n",
    "        \n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label = re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "        \n",
    "        chanel_num = data.shape[0]\n",
    "        sample_for_data = data.shape[1]\n",
    "        \n",
    "        data_filter = np.zeros_like(data)\n",
    "        fourier_domain = np.zeros_like(data)\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "    rf = rf[rf<50]\n",
    "    \n",
    "    for i in range(0,chanel_num):\n",
    "        #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "        sigA = data[i,:]\n",
    "        data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "        \n",
    "        Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "        \n",
    "        fourier_domain[i,:] = Fsig_dn\n",
    "        \n",
    "        # plt.figure(figsize=(12,8),dpi = 300)\n",
    "        # plt.subplot(1,2,1)\n",
    "        # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "        # plt.legend()\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "        # plt.legend()\n",
    "        # plt.savefig(f'{i}.png')\n",
    "        \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger = np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1 = np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bf767-186a-4a50-9d69-4251e33df802",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "def filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low,f_high):\n",
    "    \n",
    "    '''\n",
    "        در این تابع تمام کارهای فیلتر کردن سیگنال انجام می‌شود.\n",
    "          به منظور پیاده سازی روند فیلترینگ سیگنال، از فیلتر باترورث پیوسته استفاده شده است که معمولا از نوع میان گذر آن استفاده شده است. \n",
    "    '''\n",
    "    \n",
    "    data_filter = np.zeros_like(data)\n",
    "    Wn = [f_low,f_high]/np.float_(f_nyq)\n",
    "    order_filter = 4\n",
    "    (b,a) = signal.butter(order_filter, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    for channel_signal in range(0,channel_num):\n",
    "        \n",
    "        '''\n",
    "         در این قسمت چون سیگنال ما از ۲۱ کانال گرفته شده است هر کدام از کانال ها را فیلتر می‌کنیم.\n",
    "         سپس یک فور میزنیم به طول تعداد کانال ها.\n",
    "         بعد دیتای فیلتر شده را درون یک ماتریس صفر که از قبل تعریف کرده ایم می‌ریزیم.\n",
    "        '''\n",
    "        \n",
    "        data_each_channel = data[channel_signal,:]\n",
    "        data_filter[channel_signal,:] = signal.filtfilt(b,a,data_each_channel)\n",
    "\n",
    "    return data_filter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#برای استخراج ویژگی آماری از این تابع استفاده می‌کنیم.\n",
    "def statistical_features(data_for_feature_extraction):\n",
    "    \n",
    "    MEAN = np.mean(data_for_feature_extraction)\n",
    "    VAR = np.var(data_for_feature_extraction)\n",
    "    POWER = np.mean(np.power(data_for_feature_extraction,2))\n",
    "    SKEW = stats.skew(data_for_feature_extraction)\n",
    "    KUR = stats.kurtosis(data_for_feature_extraction) \n",
    "    \n",
    "    return (MEAN,VAR,POWER,SKEW,KUR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def time_feature_selection(total_bands,channel_num):\n",
    "    '''\n",
    "        داخل آرگومان اول تابع دیتای هر ۵ باند وجود دارد که میتوانیم یکی یکی آن را دریافت کنیم بعد فیچرهای هر کانال هر باند را درون یک ماتریس \n",
    "        ذخیره کنیم که در نهایت یک تنسور ۵*۲۱*۵ داریم که ۵ اول تعداد باندهاس،۲۱ تعداد کانال، ۵ تعداد فیچرهای استخراجی می‌باشد.\n",
    "         ماتریس اول داخل تنسور فیچرهای اسخراج شده از باند دلتا برای ۲۱ کانال است که یک ماتریس ۲۱* ۵ میشه که ۵ تعداد فیچرهای استخراجی می‌باشد و غیره       \n",
    "    '''\n",
    "    number_of_bands = len(total_bands)\n",
    "    num_feature = 5 #mean var power skew kur \n",
    "    time_feature_selections_total_bands = np.zeros((number_of_bands,channel_num,num_feature))\n",
    "\n",
    "    for band_num in range(number_of_bands):    \n",
    "        data = total_bands[band_num]\n",
    "        \n",
    "        for i in range(0,channel_num):\n",
    "            data_for_feature_extraction = data[i,:]\n",
    "        \n",
    "            time_feature_selections_total_bands[band_num,i,:] = statistical_features(data_for_feature_extraction)\n",
    "        \n",
    "\n",
    "    return time_feature_selections_total_bands\n",
    "    \n",
    "\n",
    "\n",
    "def seperate_band(data,channel_num,sample_for_data,fs,f_nyq):\n",
    "    #در حوزه زمان ریتم های سیگنال را استخراج می‌کنیم\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند دلتا را دارد\n",
    "    #برای هر کانال باندهای آن را استخراج می‌کنیم.\n",
    "    delta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=1,f_high=4)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند تتا را دارد\n",
    "    theta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=4,f_high=8)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند آلفا را دارد     \n",
    "    alpha = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=8,f_high=12)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند بتا را دارد\n",
    "    beta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=12,f_high=30)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که سیگنال های باند گاما در هر کانال را دارد\n",
    "    gamma = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=30,f_high=40)\n",
    "\n",
    "    return (delta,theta,alpha,beta,gamma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#از این تابع برای تبدیل فوریه گرفتن از سیگنال استفاده می‌کنیم.\n",
    "def frequency_domain(data):\n",
    "    #در این قسمت می‌خوایم از سیگنال تبدیل فوریه بگیریم و برای هر کانال این کار را می‌کنیم..\n",
    "    N = data.shape[1]\n",
    "    channel_num = data.shape[0]\n",
    "    matrix_for_save_fft_each_channel = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(0,channel_num):\n",
    "        #به ازای هر کانال یک سیگنال یک اف اف تی می‌گیریم.\n",
    "        fft_data = fft(data[i,:],N)\n",
    "        matrix_for_save_fft_each_channel[i,:] = fft_data\n",
    "    #خروجی: تبدیل فوریه هر ۲۱ کانال در یک ماتریس به طول سیگنال ورودی \n",
    "    return matrix_for_save_fft_each_channel\n",
    "\n",
    "\n",
    "def feature_selection_frequency(data):\n",
    "    \n",
    "    N = data.shape[1]\n",
    "    channel_num = data.shape[0]\n",
    "    fs = 2000\n",
    "    f_r = np.linspace(0,fs/2,int(np.floor(N/2)))\n",
    "    f_r_total = np.concatenate((f_r,f_r[::-1]))\n",
    "\n",
    "    num_feature = 5 #mean var power skew kur \n",
    "    \n",
    "    bands = 5 #delta theta alpha beta gamma\n",
    "    range_frequency = ((1,4),(4,8),(8,12),(12,30),(30,40))\n",
    "    feature_selections_total = np.zeros((bands,channel_num,num_feature)) #number_f_bands = 5\n",
    "    \n",
    "    for ch_num in range(channel_num):\n",
    "        #اطلاعات باند فرکانسی یک کانال\n",
    "        bands_number = 0 \n",
    "        \n",
    "        for a,b in range_frequency:\n",
    "\n",
    "            #ابتدا درون رزولوشن فرکانسی ما فرکانس هر باند را جدا می کنیم که به صورت ترو و فالس به ما می‌ده.\n",
    "            idx_requency_range_bands = np.logical_and(f_r >= a, f_r <= b)\n",
    "        \n",
    "            bands_range_frequency = np.abs(data[ch_num,:int(np.floor(N/2))][idx_requency_range_bands])\n",
    "\n",
    "            feature_selections_total[bands_number,ch_num,:] = statistical_features(bands_range_frequency)\n",
    "            \n",
    "            bands_number += 1 #0:delta, 1:theta, 2:alpha, 3:beta, 4:gamma    for example : for channel 1\n",
    "            \n",
    "        '''\n",
    "            خروجی یک تنسور ۳ بعدی می باشد که شامل ۵ ماتریس ۵*۲۱ است که ماتریس اول شامل فیچرهای باند دلتا برای ۲۱ کانال می‌باشد،\n",
    "           ماتریس دوم شامل فییچرهای باند تتا برای ۲۱ کانال می‌باشد\n",
    "           ماتریس سوم شامل فیچرهای باند آلفا برای ۲۱ کانال می‌ باشد\n",
    "           ماتریس چهارم شامل فیچرهای باند بتا برای ۲۱ کانال می‌باشد\n",
    "           ماتریس پنچم شامل فیچرهای باند گاما برای ۲۱ کانال می‌باشد.\n",
    "        '''\n",
    "    return feature_selections_total\n",
    "\n",
    "def feature_selectin_wavelet(data,channel_num):\n",
    "    original_sfreq = 2000\n",
    "    target_sfreq = 120\n",
    "    resampling_factor = original_sfreq/target_sfreq\n",
    "    wavelet = 'db6'\n",
    "    level = 4\n",
    "    \n",
    "    number_of_bands = 5\n",
    "    number_featuers = 5\n",
    "    wavelete_feature_extractions = np.zeros((number_of_bands, channel_num, number_featuers))\n",
    "    for i in range(channel_num):\n",
    "        \n",
    "        resampled_eeg_data = signal.resample(data[i,:],int(len(data[i,:])/resampling_factor))\n",
    "        \n",
    "        #(a4,d4,d3,d2,d1)\n",
    "        #(delta,theta,alpha,beta,gamma)\n",
    "        bands = pywt.wavedec(resampled_eeg_data, wavelet, mode='symmetric', level=level)\n",
    "\n",
    "        for index,band in enumerate(bands):\n",
    "            wavelete_feature_extractions[index,i,:] = statistical_features(band)\n",
    "    return wavelete_feature_extractions\n",
    "        \n",
    "def read_raw_data(path):\n",
    "    \n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    \n",
    "    Temp = loadmat(path)\n",
    "    a = 7e-7\n",
    "    data = Temp['EEG_Data']\n",
    "    \n",
    "    #determine the label for data\n",
    "    re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "    re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "    label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "\n",
    "    #determine channel number eeg signal i\n",
    "    channel_num = data.shape[0]\n",
    "    #determine sample number for eeg signal i\n",
    "    sample_for_data = data.shape[1]\n",
    "    \n",
    "    ####################################################denoising data \n",
    "    #determine 0 - 40 hz\n",
    "    data_denoising = filter_noisy_data(data, channel_num, sample_for_data, fs, f_nyq, f_low=1,f_high=40)\n",
    "\n",
    "    #از این به بعد این دیتای دینویز را برای اسخراج ویژگی به توابع می‌فرستیم\n",
    "    #####################################################seperate frequency band\n",
    "    (delta_time,theta_time,alpha_time,beta_time,gamma_time) = seperate_band(data_denoising,channel_num,sample_for_data,fs,f_nyq)\n",
    "    \n",
    "    #####################################################Time Feature Extraction\n",
    "    time_feature_selection_for_entire_band = time_feature_selection((delta_time,theta_time,alpha_time,beta_time,gamma_time),channel_num)\n",
    "    \n",
    "    ############################################################frequency domain + frequency Feature Extraction\n",
    "    #تبدیل فوریه داده دینویز شده\n",
    "    change_time_domain_to_frequency_domain_data = frequency_domain(data_denoising)\n",
    "    #استخراج ویژگی از حوزه فرکانس\n",
    "    frequency_feature_selection_for_entire_bands = feature_selection_frequency(change_time_domain_to_frequency_domain_data)\n",
    "    #استخراج ویژگی از حوزه ویولت\n",
    "    wavelet_feature_selection_for_entire_bands = feature_selectin_wavelet(data_denoising,channel_num)\n",
    "    \n",
    "    return label_for_subject_t, time_feature_selection_for_entire_band,frequency_feature_selection_for_entire_bands,wavelet_feature_selection_for_entire_bands\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a1101-0e55-4556-b961-aea180beb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "subject_T = glob(PATH+f'/s{1}/Directions_and_Time_T{1}/*.mat')\n",
    "data_raw_path = subject_T[0]\n",
    "print(data_raw_path)\n",
    "label,TFE,FFE,WFE = read_raw_data(data_raw_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d1fc8-a29a-48b3-b649-1cc27768f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "فیچرهای که استخراج کردیم به صورت یک تنسور می‌باشد که هر ماتریس آن اطلاعات یک باند فرکانسی است مثلا ماتریس اول شامل ۲۱ سطر است\n",
    "و ۵ ستون که به معنی اطلاعات اسخراج شده ۲۱ کانال است\n",
    "الان میخوایم اطلاعات ۵ باند را برای هر کانال پشت سر هم قرار بدهیم..\n",
    "\n",
    "TFE = Time Feature Extraction\n",
    "FFE = Frequency Feature Extraction\n",
    "WFE = wavelet Feature Extraction\n",
    "\n",
    "'''\n",
    "\n",
    "total_features = 25\n",
    "channel_num = 21\n",
    "\n",
    "concatenate_TFE_for_each_channel = np.zeros((channel_num,total_features))\n",
    "concatenate_FFE_for_each_channel = np.zeros((channel_num,total_features))\n",
    "concatenate_WFE_for_each_channel = np.zeros((channel_num,total_features))\n",
    "chan_numbers = 21\n",
    "bands_numbers = 5\n",
    "\n",
    "for chan_number in range(chan_numbers):\n",
    "    \n",
    "    LB = 0\n",
    "    HB = 5\n",
    "    \n",
    "    for band in range(bands_numbers):\n",
    "        concatenate_TFE_for_each_channel[chan_number,LB:HB] =   TFE[band,chan_number,:]\n",
    "        concatenate_FFE_for_each_channel[chan_number,LB:HB] =   FFE[band,chan_number,:]\n",
    "        concatenate_WFE_for_each_channel[chan_number,LB:HB] =   WFE[band,chan_number,:]\n",
    "        LB += 5\n",
    "        HB += 5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62d29-dc09-473e-a91c-1c8b1571793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a906f2-c02c-4de9-acf9-7dec5a2076c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9725da8-7c50-4be2-8927-bfe24260b93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
