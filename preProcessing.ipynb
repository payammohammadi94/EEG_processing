{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be9fa9c-0921-4211-9311-f6079f6d527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal,stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.fft import fft , ifft\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "\n",
    "#import mne\n",
    "\n",
    "#from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,corrmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de506256-d6fe-4b2d-973b-2a98f0866ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "\n",
    "'''\n",
    "TOTAL_PATH_T_1_3 = [\n",
    "    [[s1],[s2],...,[s6]], ---->T1\n",
    "    [[s1],[s2],...,[s6]], ---->T2\n",
    "    [[s1],[s2],...,[s6]], ---->T3\n",
    "]\n",
    "'''\n",
    "\n",
    "TOTAL_PATH_T_1_3 = []\n",
    "\n",
    "\n",
    "\n",
    "#مقدار فور را برای ۳ تحریک تنظیم می‌کنیم.\n",
    "for T in range(1,4):\n",
    "    TOTAL_PATH_SUBJECT_1_6_T = []\n",
    "    #مقدار فور را برای ۶ سابجکت تنظیم کرده ایم\n",
    "    for subject in range(1,7):\n",
    "        \"\"\"\n",
    "            در اینجا اومدیم نحوه گرفتن داده ها برای تحریک های مخنلف را جدا کردیم. برای گرفتن داده ی سابجکت ۱ تا ۶ برای تحریک شماره ۱\n",
    "            /Directions_and_Time_T1/*.mat\n",
    "            برای گرفتن داده های سابجکت شماره ۱تا ۶ تحریک شماره ۲\n",
    "            /Directions_and_Time_T2/*.mat\n",
    "            برای گرفتن داده های سابجکت ۱تا ۶ برای تحریک شماره ۳\n",
    "            /Directions_and_Time_T3/*.mat\n",
    "        \"\"\" \n",
    "        subject_T = glob(PATH+f'/s{subject}/Directions_and_Time_T{T}/*.mat')\n",
    "        TOTAL_PATH_SUBJECT_1_6_T.append(subject_T)\n",
    "    \n",
    "    TOTAL_PATH_T_1_3.append(TOTAL_PATH_SUBJECT_1_6_T)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec9ef0-6d42-4223-8ac5-f4c703c46747",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "def filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low,f_high):\n",
    "    \n",
    "    '''\n",
    "        در این تابع تمام کارهای فیلتر کردن سیگنال انجام می‌شود.\n",
    "          به منظور پیاده سازی روند فیلترینگ سیگنال، از فیلتر باترورث پیوسته استفاده شده است که معمولا از نوع میان گذر آن استفاده شده است. \n",
    "    '''\n",
    "    \n",
    "    data_filter = np.zeros_like(data)\n",
    "    Wn = [f_low,f_high]/np.float_(f_nyq)\n",
    "    order_filter = 4\n",
    "    (b,a) = signal.butter(order_filter, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    for channel_signal in range(0,channel_num):\n",
    "        \n",
    "        '''\n",
    "         در این قسمت چون سیگنال ما از ۲۱ کانال گرفته شده است هر کدام از کانال ها را فیلتر می‌کنیم.\n",
    "         سپس یک فور میزنیم به طول تعداد کانال ها.\n",
    "         بعد دیتای فیلتر شده را درون یک ماتریس صفر که از قبل تعریف کرده ایم می‌ریزیم.\n",
    "        '''\n",
    "        \n",
    "        data_each_channel = data[channel_signal,:]\n",
    "        data_filter[channel_signal,:] = signal.filtfilt(b,a,data_each_channel)\n",
    "\n",
    "    return data_filter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#برای استخراج ویژگی آماری از این تابع استفاده می‌کنیم.\n",
    "def statistical_features(data_for_feature_extraction):\n",
    "    \n",
    "    MEAN = np.mean(data_for_feature_extraction)\n",
    "    VAR = np.var(data_for_feature_extraction)\n",
    "    POWER = np.mean(np.power(data_for_feature_extraction,2))\n",
    "    SKEW = stats.skew(data_for_feature_extraction)\n",
    "    KUR = stats.kurtosis(data_for_feature_extraction) \n",
    "    \n",
    "    return (MEAN,VAR,POWER,SKEW,KUR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def time_feature_selection(total_bands,channel_num):\n",
    "    '''\n",
    "        داخل آرگومان اول تابع دیتای هر ۵ باند وجود دارد که میتوانیم یکی یکی آن را دریافت کنیم بعد فیچرهای هر کانال هر باند را درون یک ماتریس \n",
    "        ذخیره کنیم که در نهایت یک تنسور ۵*۲۱*۵ داریم که ۵ اول تعداد باندهاس،۲۱ تعداد کانال، ۵ تعداد فیچرهای استخراجی می‌باشد.\n",
    "         ماتریس اول داخل تنسور فیچرهای اسخراج شده از باند دلتا برای ۲۱ کانال است که یک ماتریس ۲۱* ۵ میشه که ۵ تعداد فیچرهای استخراجی می‌باشد و غیره       \n",
    "    '''\n",
    "    number_of_bands = len(total_bands)\n",
    "    num_feature = 5 #mean var power skew kur \n",
    "    time_feature_selections_total_bands = np.zeros((number_of_bands,channel_num,num_feature))\n",
    "\n",
    "    for band_num in range(number_of_bands):    \n",
    "        data = total_bands[band_num]\n",
    "        \n",
    "        for i in range(0,channel_num):\n",
    "            data_for_feature_extraction = data[i,:]\n",
    "        \n",
    "            time_feature_selections_total_bands[band_num,i,:] = statistical_features(data_for_feature_extraction)\n",
    "        \n",
    "\n",
    "    return time_feature_selections_total_bands\n",
    "    \n",
    "\n",
    "\n",
    "def seperate_band(data,channel_num,sample_for_data,fs,f_nyq):\n",
    "    #در حوزه زمان ریتم های سیگنال را استخراج می‌کنیم\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند دلتا را دارد\n",
    "    #برای هر کانال باندهای آن را استخراج می‌کنیم.\n",
    "    delta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=1,f_high=4)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند تتا را دارد\n",
    "    theta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=4,f_high=8)\n",
    "    \n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند آلفا را دارد     \n",
    "    alpha = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=8,f_high=12)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که همش سیگنال های باند بتا را دارد\n",
    "    beta = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=12,f_high=30)\n",
    "\n",
    "    #یک ماتریس مثلا ۲۱*۳۹۰۰ که سیگنال های باند گاما در هر کانال را دارد\n",
    "    gamma = filter_noisy_data(data,channel_num,sample_for_data,fs,f_nyq,f_low=30,f_high=40)\n",
    "\n",
    "    return (delta,theta,alpha,beta,gamma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#از این تابع برای تبدیل فوریه گرفتن از سیگنال استفاده می‌کنیم.\n",
    "def frequency_domain(data):\n",
    "    #در این قسمت می‌خوایم از سیگنال تبدیل فوریه بگیریم و برای هر کانال این کار را می‌کنیم..\n",
    "    N = data.shape[1]\n",
    "    channel_num = data.shape[0]\n",
    "    matrix_for_save_fft_each_channel = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(0,channel_num):\n",
    "        #به ازای هر کانال یک سیگنال یک اف اف تی می‌گیریم.\n",
    "        fft_data = fft(data[i,:],N)\n",
    "        matrix_for_save_fft_each_channel[i,:] = fft_data\n",
    "    #خروجی: تبدیل فوریه هر ۲۱ کانال در یک ماتریس به طول سیگنال ورودی \n",
    "    return matrix_for_save_fft_each_channel\n",
    "\n",
    "\n",
    "def feature_selection_frequency(data):\n",
    "    \n",
    "    N = data.shape[1]\n",
    "    channel_num = data.shape[0]\n",
    "    fs = 2000\n",
    "    f_r = np.linspace(0,fs/2,int(np.floor(N/2)))\n",
    "    f_r_total = np.concatenate((f_r,f_r[::-1]))\n",
    "\n",
    "    num_feature = 5 #mean var power skew kur \n",
    "    \n",
    "    bands = 5 #delta theta alpha beta gamma\n",
    "    range_frequency = ((1,4),(4,8),(8,12),(12,30),(30,40))\n",
    "    feature_selections_total = np.zeros((bands,channel_num,num_feature)) #number_f_bands = 5\n",
    "    \n",
    "    for ch_num in range(channel_num):\n",
    "        #اطلاعات باند فرکانسی یک کانال\n",
    "        bands_number = 0 \n",
    "        \n",
    "        for a,b in range_frequency:\n",
    "\n",
    "            #ابتدا درون رزولوشن فرکانسی ما فرکانس هر باند را جدا می کنیم که به صورت ترو و فالس به ما می‌ده.\n",
    "            idx_requency_range_bands = np.logical_and(f_r >= a, f_r <= b)\n",
    "        \n",
    "            bands_range_frequency = np.abs(data[ch_num,:int(np.floor(N/2))][idx_requency_range_bands])\n",
    "\n",
    "            feature_selections_total[bands_number,ch_num,:] = statistical_features(bands_range_frequency)\n",
    "            \n",
    "            bands_number += 1 #0:delta, 1:theta, 2:alpha, 3:beta, 4:gamma    for example : for channel 1\n",
    "            \n",
    "        '''\n",
    "            خروجی یک تنسور ۳ بعدی می باشد که شامل ۵ ماتریس ۵*۲۱ است که ماتریس اول شامل فیچرهای باند دلتا برای ۲۱ کانال می‌باشد،\n",
    "           ماتریس دوم شامل فییچرهای باند تتا برای ۲۱ کانال می‌باشد\n",
    "           ماتریس سوم شامل فیچرهای باند آلفا برای ۲۱ کانال می‌ باشد\n",
    "           ماتریس چهارم شامل فیچرهای باند بتا برای ۲۱ کانال می‌باشد\n",
    "           ماتریس پنچم شامل فیچرهای باند گاما برای ۲۱ کانال می‌باشد.\n",
    "        '''\n",
    "    return feature_selections_total\n",
    "\n",
    "def feature_selectin_wavelet(data,channel_num):\n",
    "    original_sfreq = 2000\n",
    "    target_sfreq = 120\n",
    "    resampling_factor = original_sfreq/target_sfreq\n",
    "    wavelet = 'db6'\n",
    "    level = 4\n",
    "    \n",
    "    number_of_bands = 5\n",
    "    number_featuers = 5\n",
    "    wavelete_feature_extractions = np.zeros((number_of_bands, channel_num, number_featuers))\n",
    "    for i in range(channel_num):\n",
    "        \n",
    "        resampled_eeg_data = signal.resample(data[i,:],int(len(data[i,:])/resampling_factor))\n",
    "        \n",
    "        #(a4,d4,d3,d2,d1)\n",
    "        #(delta,theta,alpha,beta,gamma)\n",
    "        bands = pywt.wavedec(resampled_eeg_data, wavelet, mode='symmetric', level=level)\n",
    "\n",
    "        for index,band in enumerate(bands):\n",
    "            wavelete_feature_extractions[index,i,:] = statistical_features(band)\n",
    "    return wavelete_feature_extractions\n",
    "        \n",
    "def read_raw_data(path):\n",
    "    \n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    \n",
    "    Temp = loadmat(path)\n",
    "    a = 7e-7\n",
    "    data = Temp['EEG_Data']\n",
    "    \n",
    "    #determine the label for data\n",
    "    re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "    re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "    label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "\n",
    "    #determine channel number eeg signal i\n",
    "    channel_num = data.shape[0]\n",
    "    #determine sample number for eeg signal i\n",
    "    sample_for_data = data.shape[1]\n",
    "    \n",
    "    ####################################################denoising data \n",
    "    #determine 0 - 40 hz\n",
    "    data_denoising = filter_noisy_data(data, channel_num, sample_for_data, fs, f_nyq, f_low=1,f_high=40)\n",
    "\n",
    "    #از این به بعد این دیتای دینویز را برای اسخراج ویژگی به توابع می‌فرستیم\n",
    "    #####################################################seperate frequency band\n",
    "    (delta_time,theta_time,alpha_time,beta_time,gamma_time) = seperate_band(data_denoising,channel_num,sample_for_data,fs,f_nyq)\n",
    "    \n",
    "    #####################################################Time Feature Extraction\n",
    "    time_feature_selection_for_entire_band = time_feature_selection((delta_time,theta_time,alpha_time,beta_time,gamma_time),channel_num)\n",
    "    \n",
    "    ############################################################frequency domain + frequency Feature Extraction\n",
    "    #تبدیل فوریه داده دینویز شده\n",
    "    change_time_domain_to_frequency_domain_data = frequency_domain(data_denoising)\n",
    "    #استخراج ویژگی از حوزه فرکانس\n",
    "    frequency_feature_selection_for_entire_bands = feature_selection_frequency(change_time_domain_to_frequency_domain_data)\n",
    "    #استخراج ویژگی از حوزه ویولت\n",
    "    wavelet_feature_selection_for_entire_bands = feature_selectin_wavelet(data_denoising,channel_num)\n",
    "    \n",
    "    return label_for_subject_t, time_feature_selection_for_entire_band,frequency_feature_selection_for_entire_bands,wavelet_feature_selection_for_entire_bands\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1d9ec-6fcf-46b0-b858-6e6f4675ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_os = os.getcwd()\n",
    "PATH = os.path.join(path_os,'data','v1')\n",
    "subject_T = glob(PATH+f'/s{6}/Directions_and_Time_T{1}/*.mat')\n",
    "Path_for_save = PATH+f'/s{6}/Directions_and_Time_T{1}/FetureExtraction/'\n",
    "total_features = 25\n",
    "chan_numbers = 21 #channel numbers\n",
    "bands_numbers = 5\n",
    "\n",
    "\n",
    "for index,data_raw_path in enumerate(subject_T):\n",
    "      \n",
    "\n",
    "    label,TFE,FFE,WFE = read_raw_data(data_raw_path)\n",
    "\n",
    "    '''\n",
    "        فیچرهای که استخراج کردیم به صورت یک تنسور می‌باشد که هر ماتریس آن اطلاعات یک باند فرکانسی است مثلا ماتریس اول شامل ۲۱ سطر است\n",
    "        و ۵ ستون که به معنی اطلاعات اسخراج شده ۲۱ کانال است\n",
    "        الان میخوایم اطلاعات ۵ باند را برای هر کانال پشت سر هم قرار بدهیم..\n",
    "        \n",
    "        TFE = Time Feature Extraction\n",
    "        FFE = Frequency Feature Extraction\n",
    "        WFE = wavelet Feature Extraction\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    concatenate_TFE_for_each_channel = np.zeros((chan_numbers,total_features))\n",
    "    concatenate_FFE_for_each_channel = np.zeros((chan_numbers,total_features))\n",
    "    concatenate_WFE_for_each_channel = np.zeros((chan_numbers,total_features))\n",
    "\n",
    "    \n",
    "    for chan_number in range(chan_numbers):\n",
    "    \n",
    "        LB = 0\n",
    "        HB = 5\n",
    "        \n",
    "        for band in range(bands_numbers):\n",
    "            concatenate_TFE_for_each_channel[chan_number,LB:HB] =   TFE[band,chan_number,:]\n",
    "            concatenate_FFE_for_each_channel[chan_number,LB:HB] =   FFE[band,chan_number,:]\n",
    "            concatenate_WFE_for_each_channel[chan_number,LB:HB] =   WFE[band,chan_number,:]\n",
    "            LB += 5\n",
    "            HB += 5\n",
    "\n",
    "    name = data_raw_path.split('/')[-1].split('.')[0]\n",
    "    np.save(Path_for_save+\"/TFE/\"+f\"{index}_\"+name+\"-TFE-\"+label,concatenate_TFE_for_each_channel)\n",
    "    np.save(Path_for_save+\"/FFE/\"+f\"{index}_\"+name+\"-FFE-\"+label,concatenate_FFE_for_each_channel)\n",
    "    np.save(Path_for_save+\"/WFE/\"+f\"{index}_\"+name+\"-WFE-\"+label,concatenate_WFE_for_each_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c9fae-789c-429b-8ae9-da4d0ab7432f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fe115-5e73-4567-aa1c-44000ac8618e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677ee7b-87d1-4ddb-a848-5b888857e1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a03de-82ee-4498-8f7e-aa361b861c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ed155-e4c1-4564-8e4e-cb08baee66e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94364029-68dc-4084-bea8-abba36a52e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04e08b-6680-4178-865d-241f9bf48d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9bdaf-04e0-45dd-8681-0d5cec8b60fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d86a51-5735-4ad4-a02e-75424581a175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17038b-d841-48aa-b013-e3b7458421b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024597-1103-4650-96da-a0a20df201ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e663e-cee2-4a95-b64f-100244a6ef6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7618f-6188-4f2b-928c-bacd0086f41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a644a-aa28-48c0-b82d-9c183393d77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137143a-5045-42a9-8b25-3ad05c1f1d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411b4b8-0648-4e4a-93a2-a5757fe57a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d40f1-a35d-460f-a204-d7ded2eab938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43922c48-79c9-4e0d-8753-fe0e40dd9207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f090bb8-cc54-40e8-a4b2-5c2b505260e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b76cc-7120-4fe9-9650-18e7e11c4464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe74997-f5cd-4f6e-b64a-e48df2091d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab529c63-b439-40e1-89c7-0cec56c649e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dbb49-19ae-4b05-8c6a-38d21c462c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c540b-bbe1-45d0-82c7-f570d7f699fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5d0c8-f8fc-4633-b8e3-b0ddade58a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0e77c-7a6d-41d4-81fa-79b355cf85b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b59ba-458c-452b-aff4-4f3a26c7cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee72c5-aec1-469d-a4a1-3f44c45db6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621df47e-25ab-4424-96d7-e39b7df556bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2f075-917e-493f-a65f-11c554b8d700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583015b2-f8ab-4122-97c4-a7eea57870c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocessing data without ICA\n",
    "\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "\n",
    "frequency_band = np.array[[0.1,4,8,12,30],[4,8,12,30,70]]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t1.append(re_for_get_label.replace(\"'\",''))\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        DATA_RAW.append(raw['data'][0])\n",
    "        raw.plot(show_scrollbars=False, show_scalebars=False)\n",
    "        filt_raw=raw.filter(l_freq=1, h_freq=40)\n",
    "        filt_raw.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        \n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "    \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger=np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1=np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d2122-7bfc-41eb-b0f9-31f19b762377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21\n",
    "sampling_freq = 2000\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "    \n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        data_for_subject_t.append(7e-7*Temp['EEG_Data'])\n",
    "\n",
    "    \n",
    "    \n",
    "    DATA_RAW = []\n",
    "    DATA_RAW_DOWN = []\n",
    "    \n",
    "\n",
    "    for data_for_clean in range(len(data_for_subject_t)):\n",
    "        raw = mne.io.RawArray(data_for_subject_t[data_for_clean][:,:], info)\n",
    "        raw.crop(tmax=1.5) \n",
    "        \n",
    "        filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "        \n",
    "        \n",
    "        ica = ICA(n_components=15, max_iter='auto', random_state=97)\n",
    "        ica.fit(filt_raw)\n",
    "        ica.apply(filt_raw)\n",
    "\n",
    "        raw_down = filt_raw.resample(sfreq=80)\n",
    "        #raw_down.plot(start=0,show_scrollbars=False, show_scalebars=False)\n",
    "        DATA_RAW_DOWN.append(raw_down['data'][0])\n",
    "        \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    \n",
    "    np.save(PATH_SAVE+f'Data_CLEAN_ICA_s{subject}_T{T_Couner}',DATA_RAW_DOWN)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64226a41-9ee0-470c-bc6d-ed03d68cd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[1][0]\n",
    "Temp = loadmat(s_1[20])\n",
    "data = 7e-7*Temp['EEG_Data']\n",
    "data = data.transpose()\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label = re_for_get_label.replace(\"'\",'')\n",
    "N = len(data[:,0])\n",
    "fs = 2000\n",
    "rf = np.linspace(0,fs/4,int(np.round(N/2)))\n",
    "\n",
    "fft_data = fft(data[:,0],n = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c3b78-9175-4dbc-b261-75eb162e2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(rf[1:],np.abs(fft_data[1:int(np.round(N/2))]*10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae5376-1a09-4d70-8aa5-fcd524aaeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data with ICA\n",
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "s_1 = TOTAL_PATH_T_1_3[1][3]\n",
    "Temp = loadmat(s_1[15])\n",
    "data = Temp['EEG_Data']\n",
    "\n",
    "ch_names = ['Fpz','Fp1','Fp2','Fz','F3','F4','F7','F8','Cz','C3','C4','T3','T4','Pz','P3','P4','T5','T6','O1', 'O2','Oz']\n",
    "ch_types = ['eeg'] * 21 #برای اینکه بفهمد که همه کانال ها سیگنال (ای ای جی) می‌گیرد\n",
    "\n",
    "sampling_freq = 2000\n",
    "\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage('standard_1020')\n",
    "\n",
    "raw = mne.io.RawArray(data, info)\n",
    "raw.crop(tmax=1.8)\n",
    "filt_raw = raw.filter(l_freq=1, h_freq=40)\n",
    "filt_raw.resample(sfreq=sampling_freq) #بعد از کراپ کردن دیتا دوباره می‌ایم یک نمونه برداری می‌کنیم که سایز ماتریس داده ها برای همه دیتا ها یکی شود\n",
    "filt_raw['data'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20837f88-3d49-4451-bf44-a592287b4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = TOTAL_PATH_T_1_3[0][1]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c965d-eee4-4c05-9502-623a47d42753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just one data\n",
    "#denoising for one signal\n",
    "s_1 = TOTAL_PATH_T_1_3[0][2]\n",
    "Temp = loadmat(s_1[10])\n",
    "a = 7e-7\n",
    "data = a * Temp['EEG_Data']\n",
    "re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "\n",
    "re_for_get_label=re_for_get_label.split(':')[1].strip()\n",
    "\n",
    "label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "chanel_num = data.shape[0]\n",
    "sample_for_data = data.shape[1]\n",
    "data_filter = np.zeros_like(data)\n",
    "fourier_domain = np.zeros_like(data)\n",
    "fs = 2000\n",
    "f_nyq = fs/2\n",
    "Wn = [1,40]/np.float_(f_nyq)\n",
    "(b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "rf = rf[rf<60]\n",
    "for i in range(0,chanel_num):\n",
    "    #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "    sigA = data[i,:]\n",
    "    data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "    print(signal.filtfilt(b,a,sigA).shape)\n",
    "    Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "    fourier_domain[i,:] = Fsig_dn\n",
    "    \n",
    "    # plt.figure(figsize=(12,8),dpi = 300)\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "    # plt.legend()\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f'{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3230159-c831-4481-afd7-d1699c04b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b311b-8d13-43c0-ab82-a0a3a94a9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi = 300)\n",
    "plt.subplot(1,2,1)\n",
    "plt.stem(rf,np.abs(fourier_domain[2,:rf.shape[0]]),label=f'channel {i+1}- frequency domain')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(data_filter[2,:],label=f'channel {i+1}- time domain')\n",
    "plt.legend()\n",
    "plt.savefig(f'{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea22cd-260f-44cf-992e-ac9c7c53bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Couner = 1 \n",
    "MIN = 5000\n",
    "MAX = 0\n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        for j in path_for_t[i]:\n",
    "            Temp = loadmat(j)\n",
    "            data = Temp['EEG_Data']\n",
    "            \n",
    "            a,b = data.shape\n",
    "            if b < MIN:\n",
    "                MIN = b\n",
    "            if b > MAX :\n",
    "                MAX = b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea72dfc4-bb02-4da8-91fb-019bd3a3ace6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path_for_t \u001b[38;5;129;01min\u001b[39;00m TOTAL_PATH_T_1_3:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(path_for_t)):\n\u001b[0;32m---> 95\u001b[0m         data,label_name_symbole,label_init \u001b[38;5;241m=\u001b[39m\u001b[43mpreProcessingEegSingal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_for_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/s\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Directions_and_Time_T\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mT_Couner\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/preprocessing_data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mT_Couner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     T_Couner\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \n",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m, in \u001b[0;36mpreProcessingEegSingal\u001b[0;34m(list_path_subect_i, subject, PATH_SAVE, T_Couner)\u001b[0m\n\u001b[1;32m     23\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m     24\u001b[0m f_nyq \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 25\u001b[0m Wn \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m40\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m(f_nyq)\n\u001b[1;32m     26\u001b[0m (b,a) \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mbutter(\u001b[38;5;241m4\u001b[39m, Wn, btype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbandpass\u001b[39m\u001b[38;5;124m'\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mba\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EEG/env/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "map_label = [\n",
    "        {'shoroT1':0,'balaT1':1,'paeinT1':2,'raastT1':3,'chapT1':4,'jeloT1':5,'aqabT1':6,'payanT1':7},\n",
    "        {'shoroT2':0,'balaT2':1,'paeinT2':2,'raastT2':3,'chapT2':4,'jeloT2':5,'aqabT2':6,'payanT2':7},\n",
    "        {'shoroT3':0,'balaT3':1,'paeinT3':2,'raastT3':3,'chapT3':4,'jeloT3':5,'aqabT3':6,'payanT3':7},          \n",
    "]\n",
    "\n",
    "def preProcessingEegSingal(list_path_subect_i,subject,PATH_SAVE,T_Couner):\n",
    "    '''\n",
    "        \n",
    "        \n",
    "این جا همه ی مسیرهای مربروط به هر سابجکت را به عنوان ورودی تابع می‌گیریم و تمام دیتای موجود برای سابجکت۱ و لیبل های آن را درون دوتا لیست ذخیره می‌کنیم.\n",
    "آرگومان اول تابع مسیر داده ها می‌باشد که برای سابجکت های مختلف از طریق یک فور وارد تابع می شه.\n",
    "آرگومان دوم شماره سابجکت هستش که می تونه مقادیر ۱ تا ۶ را داشته باشد\n",
    "آرگومان سوم مسیر ذخیره سازی داده ی تمیز را برا تابع می‌فرستیم که در این مسیر دیتا ذخیره بشه.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #وقتی دیتا با فرمت مت را میخونیم یک دیکشنری به ما می‌دهد که باید دیتا و لیبل ها را را جدا کنیم.\n",
    "    data_for_subject_t = []\n",
    "    label_for_subject_t1 = []\n",
    "    label_mapping_to_intiger = []\n",
    "\n",
    "    fs = 2000\n",
    "    f_nyq = fs/2\n",
    "    Wn = [1,40]/np.float(f_nyq)\n",
    "    (b,a) = signal.butter(4, Wn, btype='bandpass', output='ba')\n",
    "\n",
    "    #این فور برای گرفتن تک تک داده های سابجکت مثلا شماره یک است که هر بار آدرس تمام داده های هر سابجکت وارد تابع می‌شه و با این فور به هر کدام از آدرس ها دسترسی پیدا می‌کنیم\n",
    "    for path_mat in list_path_subect_i:\n",
    "        \n",
    "        Temp = loadmat(path_mat)\n",
    "        \n",
    "        a = 7e-7\n",
    "        \n",
    "        data = a * Temp['EEG_Data']\n",
    "        \n",
    "        re_for_get_label=re.findall(r'ID.*event_id',str(Temp['Labels'][0]))[0].split(\",\")[0]\n",
    "        \n",
    "        re_for_get_label = re_for_get_label.split(':')[1].strip()\n",
    "        \n",
    "        label_for_subject_t = re_for_get_label.replace(\"'\",'')\n",
    "        \n",
    "        chanel_num = data.shape[0]\n",
    "        sample_for_data = data.shape[1]\n",
    "        \n",
    "        data_filter = np.zeros_like(data)\n",
    "        fourier_domain = np.zeros_like(data)\n",
    "        \n",
    "        if 'Directions_and_Time_T1' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[0].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T2' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[1].get(label_for_subject_t1[-1]))\n",
    "        elif 'Directions_and_Time_T3' in PATH_SAVE:\n",
    "            label_mapping_to_intiger.append(map_label[2].get(label_for_subject_t1[-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    rf = np.linspace(0,f_nyq,int(np.round(sample_for_data/2)))\n",
    "    rf = rf[rf<50]\n",
    "    \n",
    "    for i in range(0,chanel_num):\n",
    "        #چون ۲۱ کانال داریم باید هر بار یک کانال را بگیریم بعد آ ن را دینویز کنیم بهد ازش فیلتر بگیریم.\n",
    "        sigA = data[i,:]\n",
    "        data_filter[i,:] = signal.filtfilt(b,a,sigA)\n",
    "        \n",
    "        Fsig_dn = fft(data_filter[i,:],sample_for_data)\n",
    "        \n",
    "        fourier_domain[i,:] = Fsig_dn\n",
    "        \n",
    "        # plt.figure(figsize=(12,8),dpi = 300)\n",
    "        # plt.subplot(1,2,1)\n",
    "        # plt.stem(rf,np.abs(fourier_domain[i,:rf.shape[0]]),label=f'channel {i+1} - frequency domain')\n",
    "        # plt.legend()\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.plot(data_filter[i,:],label=f'channel {i+1}- time domain ({label_for_subject_t})')\n",
    "        # plt.legend()\n",
    "        # plt.savefig(f'{i}.png')\n",
    "        \n",
    "    \n",
    "    DATA_RAW_DOWN = np.array(DATA_RAW_DOWN)\n",
    "    label_mapping_to_intiger = np.array(label_mapping_to_intiger)\n",
    "    label_for_subject_t1 = np.array(label_for_subject_t1)\n",
    "    \n",
    "    #np.save(PATH_SAVE+f'Data_CLEAN_s{subject}_T{T_Couner}',DATA_RAW_DOWN) #save clean data\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_symbol',label_for_subject_t1) # save label of each sample (balaT1,payanT1,...)\n",
    "    #np.save(PATH_SAVE+f'LABEL_subject_{subject}_intiger',label_mapping_to_intiger) #save label of each sample mapping to init (0,1,2,3)\n",
    "    \n",
    "    return DATA_RAW_DOWN,label_for_subject_t1,label_mapping_to_intiger\n",
    "\n",
    "    \n",
    "T_Couner = 1 \n",
    "for path_for_t in TOTAL_PATH_T_1_3:\n",
    "    for i in range(len(path_for_t)):\n",
    "        data,label_name_symbole,label_init =preProcessingEegSingal(path_for_t[i],i+1,PATH+f'/s{i+1}/Directions_and_Time_T{T_Couner}/preprocessing_data/',T_Couner)\n",
    "    T_Couner+=1  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92bf767-186a-4a50-9d69-4251e33df802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "625a1101-0e55-4556-b961-aea180beb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7452/3561504416.py:109: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  matrix_for_save_fft_each_channel[i,:] = fft_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d1fc8-a29a-48b3-b649-1cc27768f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4178b780-82e4-4017-860a-01d348e99986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
